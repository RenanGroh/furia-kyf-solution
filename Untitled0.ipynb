{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EAE39IDpemEXYal1PRzdEvCxVEuQIUaL",
      "authorship_tag": "ABX9TyNTpCwmPe5qWPag8epcO+sK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenanGroh/furia-kyf-solution/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inicio do projeto\n",
        "- codigos iniciais"
      ],
      "metadata": {
        "id": "kOxl6AnghoyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai python-dotenv beautifulsoup4 requests pandas -q"
      ],
      "metadata": {
        "id": "RS9uAfD9Rudl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Opcional: Verificar o diret√≥rio atual\n",
        "print(f\"Diret√≥rio atual: {os.getcwd()}\") # /content\n",
        "\n",
        "# ==> Precisa de um .env com gemini key no dir /content <===\n",
        "\n",
        "# carregar o .env\n",
        "# load_dotenv() procura no diret√≥rio atual ou em diret√≥rios pais\n",
        "# e retorna True se encontrar e carregar, False caso contr√°rio.\n",
        "dotenv_loaded = load_dotenv()\n",
        "\n",
        "# Definir vari√°veis fora do if para garantir que existam (com valor None se falhar)\n",
        "gemini_api_key = None\n",
        "pandascore_api_key = None # talvez use\n",
        "furia_team_id = None # talvez use\n",
        "\n",
        "if dotenv_loaded:\n",
        "    print(\".env carregado com sucesso!\")\n",
        "\n",
        "    # ====> CARREGA O ID DA GEMINI 1.5 <====\n",
        "    gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
        "    print(f\"Chave Gemini carregada: {'Sim' if gemini_api_key else 'N√£o -> Verifique o nome GEMINI_API_KEY no .env'}\")\n",
        "\n",
        "    # ====> CARREGA A CHAVE PANDASCORE <====\n",
        "    pandascore_api_key = os.getenv('PANDASCORE_API_KEY')\n",
        "    print(f\"Chave PandaScore carregada: {'Sim' if pandascore_api_key else 'N√£o -> Verifique o nome PANDASCORE_API_KEY no .env'}\")\n",
        "\n",
        "    # ====> CARREGA O ID DA FURIA <====\n",
        "    furia_team_id_str = os.getenv('FURIA_CS2_TEAM_ID')\n",
        "    if furia_team_id_str:\n",
        "        furia_team_id = int(furia_team_id_str) # Converte para inteiro se existir\n",
        "        print(f\"ID Time FURIA carregado: {furia_team_id}\")\n",
        "    else:\n",
        "        print(\"ID Time FURIA (FURIA_CS2_TEAM_ID) n√£o encontrado no .env\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"Arquivo .env n√£o foi encontrado ou n√£o p√¥de ser carregado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJrJgT75dgis",
        "outputId": "fa0ffe19-dcfa-4444-e6c7-1d9185316db4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diret√≥rio atual: /content\n",
            ".env carregado com sucesso!\n",
            "Chave Gemini carregada: Sim\n",
            "Chave PandaScore carregada: Sim\n",
            "ID Time FURIA carregado: 124530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Instala√ß√£o OCR (Reconhecimento √ìtico de Caracteres) ---\n",
        "#(Executar uma vez por sess√£o)\n",
        "print(\"Instalando Tesseract OCR...\")\n",
        "!sudo apt-get update -qq\n",
        "!sudo apt-get install tesseract-ocr tesseract-ocr-por -qq # Instala Tesseract e pacote de linguagem Portugu√™s\n",
        "!pip install pytesseract Pillow -q # Instala wrapper Python e Pillow para manipula√ß√£o de imagem\n",
        "print(\"Tesseract e pytesseract instalados.\")\n",
        "\n",
        "# Importar ap√≥s instala√ß√£o\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import re # Para limpeza de texto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l90kj1ZQl89b",
        "outputId": "14fcf937-ee4a-4536-da35-7ae2c42af0f3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando Tesseract OCR...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Tesseract e pytesseract instalados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge #2: Know Your Fan (FURIA)\n",
        "\n",
        "Este notebook demonstra uma solu√ß√£o para coletar e analisar informa√ß√µes sobre um f√£ de e-sports, focando na FURIA, conforme proposto no desafio. Devido √† sensibilidade de dados PII e limita√ß√µes de API, v√°rias etapas ser√£o simuladas."
      ],
      "metadata": {
        "id": "2sbhhmWPR9I6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa 1: Valida√ß√£o de Links de Perfis E-sports com IA\n",
        "\n",
        "Nesta se√ß√£o, vamos implementar a funcionalidade para:\n",
        "1. Coletar uma URL de perfil de e-sports (ex: Liquipedia).\n",
        "2. Buscar o conte√∫do HTML dessa p√°gina (Web Scraping).\n",
        "3. Extrair texto relevante da p√°gina.\n",
        "4. Enviar o texto extra√≠do para a API do Google Gemini para an√°lise.\n",
        "5. Verificar se o perfil √© relevante para um f√£ da FURIA / CS."
      ],
      "metadata": {
        "id": "hnPv1V0UaYUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Bloco de Configura√ß√£o ---\n",
        "\n",
        "# 1. Importar bibliotecas\n",
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "import google.generativeai as genai\n",
        "print(\"Bibliotecas importadas.\")\n",
        "\n",
        "# 2. Carregar vari√°veis do .env (API Keys)\n",
        "# Certifique-se de ter feito upload do seu arquivo .env para esta sess√£o!\n",
        "dotenv_loaded = load_dotenv()\n",
        "gemini_api_key = None\n",
        "if dotenv_loaded:\n",
        "    print(\".env encontrado e carregado.\")\n",
        "    gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
        "else:\n",
        "    print(\"AVISO: Arquivo .env n√£o encontrado. Fa√ßa o upload ou use Colab Secrets.\")\n",
        "\n",
        "# 3. Configurar a API Gemini (s√≥ se a chave foi carregada)\n",
        "gemini_model = None # Define como None inicialmente\n",
        "if gemini_api_key:\n",
        "    try:\n",
        "        genai.configure(api_key=gemini_api_key)\n",
        "        gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest') # Ou o modelo que preferir\n",
        "        print(\"Modelo Gemini configurado com sucesso.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao configurar Gemini: {e}\")\n",
        "        gemini_api_key = None # Anula a chave se a configura√ß√£o falhar\n",
        "else:\n",
        "    print(\"Chave API Gemini n√£o encontrada. An√°lise por IA desativada.\")\n",
        "\n",
        "print(\"--- Configura√ß√£o Conclu√≠da ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMo7awA1aj03",
        "outputId": "c7aba700-e320-44da-f1b1-8293b70d8445"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas.\n",
            ".env encontrado e carregado.\n",
            "Modelo Gemini configurado com sucesso.\n",
            "--- Configura√ß√£o Conclu√≠da ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Coleta da URL ---\n",
        "profile_url = \"\" # Garante que a vari√°vel existe\n",
        "try:\n",
        "  profile_url = input(\"‚û°Ô∏è Cole a URL completa do perfil de e-sports (Ex: uma p√°gina da Liquipedia): \")\n",
        "  if not profile_url.startswith('http'):\n",
        "      print(\"‚ö†Ô∏è Aviso: URL parece inv√°lida. Certifique-se de incluir http:// ou https://\")\n",
        "  print(f\"\\nURL que ser√° analisada: {profile_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro ao ler a URL: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GDlqzKoeD8Z",
        "outputId": "e358a135-9d51-42d7-c4e6-2d90602f185a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚û°Ô∏è Cole a URL completa do perfil de e-sports (Ex: uma p√°gina da Liquipedia): https://liquipedia.net/counterstrike/FURIA\n",
            "\n",
            "URL que ser√° analisada: https://liquipedia.net/counterstrike/FURIA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Web Scraping ---\n",
        "\n",
        "extracted_text = \"\" # Vari√°vel para guardar o texto extra√≠do\n",
        "page_title = \"\"\n",
        "scrape_success = False # Flag para saber se deu certo\n",
        "\n",
        "if profile_url: # S√≥ tenta se uma URL foi fornecida\n",
        "    headers = { # Simula um navegador\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "    try:\n",
        "        print(f\"\\n‚è≥ Buscando conte√∫do de: {profile_url}\")\n",
        "        time.sleep(1) # Pausa de 1 segundo\n",
        "        response = requests.get(profile_url, headers=headers, timeout=15) # Timeout aumentado\n",
        "        response.raise_for_status() # Verifica erros HTTP (4xx, 5xx)\n",
        "\n",
        "        print(\"‚úÖ P√°gina buscada com sucesso!\")\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Tenta pegar o t√≠tulo\n",
        "        page_title = soup.title.string if soup.title else \"T√≠tulo n√£o encontrado\"\n",
        "        print(f\"T√≠tulo da P√°gina: {page_title}\")\n",
        "\n",
        "        # --- !!! PONTO CR√çTICO: EXTRA√á√ÉO DE CONTE√öDO !!! ---\n",
        "        # Esta parte DEPENDE MUITO do site (Liquipedia, HLTV, etc.)\n",
        "        # Voc√™ PRECISA inspecionar o HTML do site alvo com F12 no navegador\n",
        "        # para achar os seletores corretos (IDs, classes das divs principais)\n",
        "\n",
        "        # Exemplo para LIQUIPEDIA:\n",
        "        content_div = soup.find('div', id='bodyContent') # Tenta achar <div id=\"bodyContent\">\n",
        "        if not content_div:\n",
        "             content_div = soup.find('div', class_='mw-parser-output') # Outra possibilidade comum em wikis\n",
        "\n",
        "        # Fallback gen√©rico (pegar o corpo todo)\n",
        "        if not content_div:\n",
        "             content_div = soup.find('body')\n",
        "        # --- FIM DO PONTO CR√çTICO ---\n",
        "\n",
        "        if content_div:\n",
        "            # Extrai texto, une as linhas e remove espa√ßos m√∫ltiplos\n",
        "            extracted_text = ' '.join(content_div.get_text(separator=' ', strip=True).split())\n",
        "            scrape_success = True # Marca que a extra√ß√£o (de algo) deu certo\n",
        "            print(f\"\\nTexto extra√≠do (primeiros 1500 chars): \\n'{extracted_text[:1500]}...'\")\n",
        "        else:\n",
        "            extracted_text = \"‚ùå Erro: N√£o foi poss√≠vel encontrar um container de conte√∫do principal na p√°gina.\"\n",
        "            print(extracted_text)\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"‚ùå Erro: Timeout ao tentar conectar a {profile_url}\")\n",
        "        extracted_text = f\"Erro: Timeout ao buscar a URL.\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ùå Erro ao buscar a URL: {e}\")\n",
        "        extracted_text = f\"Erro ao buscar a URL: {e}\"\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro inesperado durante o scraping: {e}\")\n",
        "        extracted_text = f\"Erro inesperado durante o scraping: {e}\"\n",
        "\n",
        "    # Limita o tamanho para enviar √† IA\n",
        "    max_length = 5000\n",
        "    if len(extracted_text) > max_length:\n",
        "        print(f\"\\n‚úÇÔ∏è Aviso: Texto extra√≠do truncado em {max_length} caracteres.\")\n",
        "        extracted_text = extracted_text[:max_length]\n",
        "else:\n",
        "    print(\"Nenhuma URL fornecida para fazer scraping.\")\n",
        "\n",
        "print(\"\\n--- Scraping Conclu√≠do ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82mVebozeNtR",
        "outputId": "e240b6d5-63a8-4e36-e1f8-2a18edc58f78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚è≥ Buscando conte√∫do de: https://liquipedia.net/counterstrike/FURIA\n",
            "‚úÖ P√°gina buscada com sucesso!\n",
            "T√≠tulo da P√°gina: FURIA - Liquipedia Counter-Strike Wiki\n",
            "\n",
            "Texto extra√≠do (primeiros 1500 chars): \n",
            "'From Liquipedia Counter-Strike Wiki FURIA FURIA Academy FURIA Female Overview Results Matches [ e ][ h ] FURIA Team Information Location: Brazil Region: South America Founders: Jaime P√°dua Andr√© Akkari Cristian Guedes Nicholas Nogueira CEO: Jaime P√°dua Andr√© Akkari Manager: guerri Alexia Midori In-Game Leader: FalleN Coaches: sidde Hepa KrizzeN Approx. Total Winnings: $2,044,173 Games: Global Offensive Counter-Strike 2 Links History Created: : 2017-08-10 : 2017-08-10 Upcoming Tournaments PGL Astana 2025 2025-05-10 00:00:00 UTC May 10 - 18 Intel Extreme Masters Dallas 2025 2025-05-19 00:00:00 UTC May 19 - 25 BLAST.tv Austin Major 2025 2025-06-02 00:00:00 UTC Jun 02 - 22 FURIA (formerly stylized as FURIA Esports ) is a Brazilian esports organization that was founded in August 2017. Contents 1 Timeline 2 Player Roster 2.1 Active 2.2 Inactive 2.3 Former 2.4 Former 3 Organization 3.1 Active 3.2 Former 4 Results 5 Interviews 6 Gallery 6.1 Rosters 7 References Timeline [ edit ] 2017 2018 2019 2020 2021 2022 2023 2024 2025 Show All August 10th - FURIA Esports sign spacca , prd , guerri , caike , VINI and Sllayer , the latter as coach. [1] October 2nd - FURIA Esports part ways with caike . [2] October 7th - FURIA Esports sign bld V . [3] [4] November 8th - FURIA Esports part ways with prd and Sllayer as they sign yuurih . [5] [6] January 17th - FURIA Esports part ways with VINI and sign s1 as his replacement. [7] [8] February 2nd - FURIA Esports move guerri to a coaching position. [9]...'\n",
            "\n",
            "‚úÇÔ∏è Aviso: Texto extra√≠do truncado em 5000 caracteres.\n",
            "\n",
            "--- Scraping Conclu√≠do ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- An√°lise com IA (Gemini) ---\n",
        "\n",
        "analysis_result = \"An√°lise n√£o realizada.\" # Mensagem padr√£o\n",
        "\n",
        "# Verifica se o scraping teve algum sucesso E se a API Gemini est√° pronta\n",
        "if scrape_success and gemini_model:\n",
        "    print(\"\\nü§ñ Enviando texto para an√°lise do Gemini...\")\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "        **Tarefa:** Analisar a relev√¢ncia do conte√∫do web extra√≠do abaixo para um f√£ brasileiro de Counter-Strike (CS2/CS:GO), com foco especial na equipe FURIA.\n",
        "\n",
        "        **T√≠tulo da P√°gina:** \"{page_title}\"\n",
        "\n",
        "        **Texto Extra√≠do:**\n",
        "        ---\n",
        "        {extracted_text}\n",
        "        ---\n",
        "\n",
        "        **Por favor, responda:**\n",
        "        1.  **Relev√¢ncia Geral (E-sports/CS):** O conte√∫do √© sobre e-sports? Especificamente sobre Counter-Strike? (Sim/N√£o/Parcialmente, Justifique brevemente)\n",
        "        2.  **Relev√¢ncia (FURIA):** H√° men√ß√µes diretas √† equipe FURIA ou a jogadores not√≥rios associados a ela? (Sim/N√£o/Possivelmente, Liste exemplos se Sim)\n",
        "        3.  **Conclus√£o para F√£ da FURIA:** Qual a relev√¢ncia deste perfil/p√°gina especificamente para um torcedor da FURIA? (Ex: Alta, M√©dia, Baixa, Nenhuma. Explique o porqu√™)\n",
        "        4.  **Informa√ß√µes atuais:** Qual √© a line-up atual do time, quem s√£o os novos integrantes?\n",
        "\n",
        "        **Observa√ß√£o:** Se o texto parecer incompleto ou indicar um erro de scraping, leve isso em considera√ß√£o na sua an√°lise.\n",
        "        \"\"\"\n",
        "\n",
        "        # Fazer a chamada para a API\n",
        "        response_gemini = gemini_model.generate_content(prompt)\n",
        "\n",
        "        print(\"\\n--- ‚úÖ An√°lise do Gemini Recebida ---\")\n",
        "        # Tratamento da resposta (lidando com poss√≠veis bloqueios)\n",
        "        try:\n",
        "             analysis_result = response_gemini.text\n",
        "             print(analysis_result)\n",
        "        except ValueError:\n",
        "             # Se n√£o houver 'text', verificar 'prompt_feedback'\n",
        "             if response_gemini.prompt_feedback.block_reason:\n",
        "                   analysis_result = f\"‚ùå An√°lise bloqueada pelo filtro de seguran√ßa: {response_gemini.prompt_feedback.block_reason}\"\n",
        "                   print(analysis_result)\n",
        "             else:\n",
        "                   analysis_result = \"‚ùå Erro: Gemini retornou uma resposta inesperada (sem texto ou bloqueio claro).\"\n",
        "                   print(analysis_result)\n",
        "        except Exception as e_resp:\n",
        "            analysis_result = f\"‚ùå Erro ao processar resposta do Gemini: {e_resp}\"\n",
        "            print(analysis_result)\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Erro ao chamar a API Gemini: {e}\")\n",
        "        analysis_result = f\"Erro ao chamar a API Gemini: {e}\"\n",
        "elif not scrape_success:\n",
        "    analysis_result = \"An√°lise n√£o realizada devido a erro no scraping ou falta de conte√∫do.\"\n",
        "    print(f\"\\n{analysis_result}\")\n",
        "elif not gemini_model:\n",
        "    analysis_result = \"An√°lise n√£o realizada: API Gemini n√£o configurada.\"\n",
        "    print(f\"\\n{analysis_result}\")\n",
        "\n",
        "print(\"\\n--- Valida√ß√£o por IA Conclu√≠da ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "fbbcjw3teljH",
        "outputId": "2edb9f69-dc6a-4030-ff80-3d7c1b216573"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ Enviando texto para an√°lise do Gemini...\n",
            "\n",
            "--- ‚úÖ An√°lise do Gemini Recebida ---\n",
            "1. **Relev√¢ncia Geral (E-sports/CS):** Sim. O conte√∫do √© explicitamente sobre a organiza√ß√£o de e-sports FURIA e sua participa√ß√£o em Counter-Strike: Global Offensive (CS:GO) e, mais recentemente, CS2.  A p√°gina √© uma entrada de uma wiki dedicada a Counter-Strike, fornecendo um hist√≥rico detalhado da equipe.\n",
            "\n",
            "2. **Relev√¢ncia (FURIA):** Sim.  O texto inteiro √© sobre a FURIA.  Menciona diversos jogadores que fizeram parte da equipe ao longo dos anos, incluindo os atuais, como KSCERATO, yuurih, FalleN, e molodoy.  Al√©m disso, lista informa√ß√µes sobre a organiza√ß√£o, incluindo fundadores, ger√™ncia, e hist√≥rico de resultados.\n",
            "\n",
            "3. **Conclus√£o para F√£ da FURIA:** Alta. Este perfil da Liquipedia √© uma fonte inestim√°vel de informa√ß√£o para um f√£ da FURIA.  Ele fornece um hist√≥rico completo da equipe, desde sua funda√ß√£o, incluindo mudan√ßas na line-up, contrata√ß√µes e dispensas de jogadores, al√©m da data de entrada e sa√≠da de cada um. Isso permite ao torcedor acompanhar a trajet√≥ria da equipe e entender sua evolu√ß√£o.  A informa√ß√£o sobre os pr√≥ximos torneios e o detalhamento das datas tamb√©m √© muito relevante.\n",
            "\n",
            "4. **Informa√ß√µes atuais:** De acordo com o texto extra√≠do (que parece estar incompleto ou com erros de scraping, pois algumas datas de entrada de jogadores n√£o batem com o texto), a line-up atual da FURIA em CS2/CS:GO √©:\n",
            "\n",
            "* yuurih (Yuri Boian)\n",
            "* KSCERATO (Kaike Cerato)\n",
            "* FalleN (Gabriel Toledo)\n",
            "* molodoy (Danil Golubenko)\n",
            "* YEKINDAR (Mareks Gaƒºinskis) (como stand-in)\n",
            "\n",
            "Os novos integrantes recentes seriam molodoy e YEKINDAR (como stand-in), al√©m de FalleN que retornou ao time.  √â importante notar que a precis√£o dessa informa√ß√£o depende da completude e precis√£o dos dados fornecidos pelo trecho do texto.  A falta de informa√ß√µes e a inconsist√™ncia de datas sugerem que o texto foi truncado ou cont√©m erros.  Recomenda-se consultar a p√°gina original na Liquipedia para ter certeza da line-up atual.\n",
            "\n",
            "\n",
            "--- Valida√ß√£o por IA Conclu√≠da ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa 2: Coleta de Dados B√°sicos\n",
        "\n",
        "Nesta se√ß√£o, coletamos informa√ß√µes b√°sicas do f√£.\n",
        "**Importante:** Dados Pessoais Identific√°veis (PII) como nome completo, CPF e endere√ßo residencial s√£o **extremamente sens√≠veis** e n√£o devem ser coletados ou armazenados em projetos como este por raz√µes de privacidade e seguran√ßa (LGPD). **Portanto, esses dados ser√£o representados por valores FICT√çCIOS apenas para fins de demonstra√ß√£o.**\n",
        "\n",
        "Coletaremos interativamente alguns interesses n√£o sens√≠veis.\n"
      ],
      "metadata": {
        "id": "iuIk1ZNfiSyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Coleta de Dados B√°sicos ---\n",
        "\n",
        "print(\"--- Iniciando Coleta de Dados B√°sicos ---\")\n",
        "\n",
        "# Dicion√°rio para armazenar os dados do f√£\n",
        "fan_data = {}\n",
        "\n",
        "# ** DADOS PII FICT√çCIOS **\n",
        "fan_data['nome_completo'] = \"Alex Silva (Fict√≠cio)\" # Nome Fict√≠cio\n",
        "fan_data['cidade_estado'] = \"S√£o Paulo, SP (Fict√≠cio)\" # Apenas Cidade/Estado\n",
        "fan_data['cpf'] = \"Omitido/Fict√≠cio (N√£o Coletado)\" # Indicar que n√£o √© real/coletado\n",
        "\n",
        "print(f\"\\nDados Pessoais (Fict√≠cios):\")\n",
        "print(f\"  Nome: {fan_data['nome_completo']}\")\n",
        "print(f\"  Localiza√ß√£o: {fan_data['cidade_estado']}\")\n",
        "print(f\"  CPF: {fan_data['cpf']}\")\n",
        "\n",
        "print(\"\\n--- Coleta de Interesses ---\")\n",
        "\n",
        "# Coleta de dados n√£o sens√≠veis via input()\n",
        "try:\n",
        "  fan_data['jogo_favorito'] = input(\"‚û°Ô∏è Qual seu jogo de e-sport favorito? (Ex: CS2, LoL, Valorant): \")\n",
        "  fan_data['jogador_furia_fav'] = input(\"‚û°Ô∏è Qual seu jogador favorito da FURIA (CS2)? (Ex: FalleN, KSCERATO): \")\n",
        "  fan_data['assistiu_evento_ano'] = input(\"‚û°Ô∏è Assistiu a algum evento presencial de e-sports no √∫ltimo ano? (Sim/N√£o): \")\n",
        "  fan_data['comprou_item_ano'] = input(\"‚û°Ô∏è Comprou algum item relacionado a e-sports (jogo, skin, camisa de time) no √∫ltimo ano? (Sim/N√£o): \")\n",
        "  fan_data['tempo_acompanha_furia'] = input(\"‚û°Ô∏è H√° quanto tempo voc√™ acompanha a FURIA? (Ex: 1 ano, desde 2020): \")\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro durante a coleta de interesses: {e}\")\n",
        "\n",
        "print(\"\\n--- Coleta de Interesses Conclu√≠da ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oiho9vL5ilwu",
        "outputId": "caebcd2e-b38b-498e-9025-cf7fd299650c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando Coleta de Dados B√°sicos ---\n",
            "\n",
            "Dados Pessoais (Fict√≠cios):\n",
            "  Nome: Alex Silva (Fict√≠cio)\n",
            "  Localiza√ß√£o: S√£o Paulo, SP (Fict√≠cio)\n",
            "  CPF: Omitido/Fict√≠cio (N√£o Coletado)\n",
            "\n",
            "--- Coleta de Interesses ---\n",
            "‚û°Ô∏è Qual seu jogo de e-sport favorito? (Ex: CS2, LoL, Valorant): c2\n",
            "‚û°Ô∏è Qual seu jogador favorito da FURIA (CS2)? (Ex: FalleN, KSCERATO): fallen\n",
            "‚û°Ô∏è Assistiu a algum evento presencial de e-sports no √∫ltimo ano? (Sim/N√£o): nao\n",
            "‚û°Ô∏è Comprou algum item relacionado a e-sports (jogo, skin, camisa de time) no √∫ltimo ano? (Sim/N√£o): sim\n",
            "‚û°Ô∏è H√° quanto tempo voc√™ acompanha a FURIA? (Ex: 1 ano, desde 2020): 4anos\n",
            "\n",
            "--- Coleta de Interesses Conclu√≠da ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa 2.1: Verifica√ß√£o de Identidade (SIMULADA)\n",
        "\n",
        "A verifica√ß√£o de identidade real envolveria o upload seguro de um documento (RG/CNH) e o uso de IA (OCR para ler dados, an√°lise de imagem para seguran√ßa, possivelmente reconhecimento facial). Isso requer APIs especializadas e pagas (ex: AWS Rekognition, Sumsub, etc.) e lida com dados **extremamente sens√≠veis**.\n",
        "\n",
        "**Para este desafio, apenas SIMULAREMOS o resultado desse processo.** Assumiremos que o usu√°rio fez o upload e a IA validou com sucesso."
      ],
      "metadata": {
        "id": "I7EnLycIi3Ja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Simula√ß√£o de Verifica√ß√£o de ID com OCR ---\n",
        "\n",
        "id_verified_status = False # Status final da verifica√ß√£o\n",
        "extracted_ocr_text = \"\"\n",
        "structured_data_from_ocr = {} # Dicion√°rio para dados estruturados pela IA\n",
        "\n",
        "# --- 1. Simular Upload e Ler Imagem com OCR ---\n",
        "uploaded_file_path = 'doc_exemplo.jpeg' # <<< Coloque o nome EXATO do arquivo que voc√™ fez upload\n",
        "\n",
        "print(\"\\n--- Iniciando Simula√ß√£o de Verifica√ß√£o de ID ---\")\n",
        "if os.path.exists(uploaded_file_path):\n",
        "    print(f\"  Arquivo '{uploaded_file_path}' encontrado (simulando upload).\")\n",
        "    try:\n",
        "        print(\"  Tentando ler texto da imagem com Tesseract OCR (pode levar um momento)...\")\n",
        "        # Usa pytesseract para extrair texto em portugu√™s ('por')\n",
        "        extracted_ocr_text = pytesseract.image_to_string(Image.open(uploaded_file_path), lang='por')\n",
        "\n",
        "        if extracted_ocr_text.strip(): # Verifica se algum texto foi extra√≠do\n",
        "             print(\"‚úÖ OCR conclu√≠do. Texto extra√≠do:\")\n",
        "             print(\"-\"*25)\n",
        "             print(extracted_ocr_text)\n",
        "             print(\"-\"*25)\n",
        "\n",
        "             # Marca como \"parcialmente verificado\" baseado no OCR\n",
        "             id_verified_status = True # Consideramos sucesso se OCR leu algo\n",
        "        else:\n",
        "             print(\"‚ö†Ô∏è Aviso: OCR n√£o conseguiu extrair texto significativo da imagem.\")\n",
        "             extracted_ocr_text = \"OCR n√£o extraiu texto.\"\n",
        "\n",
        "\n",
        "    except pytesseract.TesseractNotFoundError:\n",
        "        print(\"‚ùå Erro: Tesseract OCR n√£o est√° instalado ou n√£o encontrado no PATH.\")\n",
        "        print(\"    Certifique-se de ter executado a c√©lula de instala√ß√£o do Tesseract.\")\n",
        "        extracted_ocr_text = \"Erro na instala√ß√£o do Tesseract.\"\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao processar imagem com OCR: {e}\")\n",
        "        extracted_ocr_text = f\"Erro no OCR: {e}\"\n",
        "\n",
        "else:\n",
        "  print(f\"‚ùå Falha: Arquivo de exemplo '{uploaded_file_path}' n√£o encontrado.\")\n",
        "  print(\"    Fa√ßa o upload da imagem de exemplo.\")\n",
        "  extracted_ocr_text = \"Arquivo de exemplo n√£o encontrado.\"\n",
        "\n",
        "\n",
        "# --- 2. (Opcional) Usar Gemini para Estruturar Dados do OCR ---\n",
        "if id_verified_status and gemini_model and extracted_ocr_text.strip() and extracted_ocr_text != \"OCR n√£o extraiu texto.\":\n",
        "     print(\"\\nü§ñ Tentando estruturar dados do OCR com Gemini...\")\n",
        "     try:\n",
        "          prompt_structure = f\"\"\"\n",
        "          Dado o seguinte texto extra√≠do por OCR de uma imagem de documento de identidade (pode conter erros de leitura),\n",
        "          tente extrair e estruturar as seguintes informa√ß√µes em formato JSON (use \"N/A\" se n√£o encontrar):\n",
        "          - nome_completo\n",
        "          - numero_cpf (se houver)\n",
        "          - numero_rg (se houver)\n",
        "          - data_nascimento (formato DD/MM/AAAA se poss√≠vel)\n",
        "          - nome_mae (se houver)\n",
        "          - nome_pai (se houver)\n",
        "\n",
        "          **Texto OCR:**\n",
        "          ---\n",
        "          {extracted_ocr_text}\n",
        "          ---\n",
        "\n",
        "          **JSON Estruturado:**\n",
        "          \"\"\"\n",
        "          response_structure = gemini_model.generate_content(prompt_structure)\n",
        "\n",
        "          print(\"\\n--- Estrutura√ß√£o IA (Tentativa) ---\")\n",
        "          try:\n",
        "                structured_text = response_structure.text\n",
        "                print(structured_text)\n",
        "                # Tentar extrair o JSON da resposta da IA (pode precisar de limpeza/regex)\n",
        "                # Esta parte √© mais complexa e pode falhar\n",
        "                try:\n",
        "                     # Tenta encontrar algo que se pare√ßa com um JSON\n",
        "                     import json\n",
        "                     json_match = re.search(r'\\{.*\\}', structured_text, re.DOTALL)\n",
        "                     if json_match:\n",
        "                          structured_data_from_ocr = json.loads(json_match.group())\n",
        "                          print(\"\\nJSON Extra√≠do:\")\n",
        "                          print(structured_data_from_ocr)\n",
        "                     else:\n",
        "                          print(\"\\nN√£o foi poss√≠vel extrair JSON da resposta da IA.\")\n",
        "                          structured_data_from_ocr = {\"erro\": \"N√£o foi poss√≠vel extrair JSON.\"}\n",
        "                except json.JSONDecodeError:\n",
        "                     print(\"\\nErro ao decodificar JSON da resposta da IA.\")\n",
        "                     structured_data_from_ocr = {\"erro\": \"JSON inv√°lido na resposta.\"}\n",
        "                except Exception as json_e:\n",
        "                     print(f\"\\nErro inesperado ao processar JSON: {json_e}\")\n",
        "                     structured_data_from_ocr = {\"erro\": \"Erro ao processar JSON.\"}\n",
        "\n",
        "          except ValueError: # Trata bloqueio de seguran√ßa\n",
        "               if response_structure.prompt_feedback.block_reason:\n",
        "                   structured_text = f\"‚ùå Bloqueado: {response_structure.prompt_feedback.block_reason}\"\n",
        "                   print(structured_text)\n",
        "               else:\n",
        "                   structured_text = \"‚ùå Erro: Resposta inesperada.\"\n",
        "                   print(structured_text)\n",
        "               structured_data_from_ocr = {\"erro\": structured_text}\n",
        "          except Exception as e_resp:\n",
        "                structured_data_from_ocr = {\"erro\": f\"Erro processando resposta: {e_resp}\"}\n",
        "                print(f\"‚ùå Erro ao processar resposta Gemini: {e_resp}\")\n",
        "\n",
        "     except Exception as e:\n",
        "          print(f\"\\n‚ùå Erro ao chamar API Gemini para estrutura√ß√£o: {e}\")\n",
        "          structured_data_from_ocr = {\"erro\": f\"Erro API Gemini: {e}\"}\n",
        "\n",
        "elif not gemini_model:\n",
        "    print(\"\\nAPI Gemini n√£o configurada, pulando estrutura√ß√£o de dados.\")\n",
        "    structured_data_from_ocr = {\"aviso\": \"IA n√£o dispon√≠vel para estrutura√ß√£o.\"}\n",
        "elif not id_verified_status:\n",
        "     structured_data_from_ocr = {\"aviso\": \"OCR falhou, sem dados para estruturar.\"}\n",
        "# Armazena os resultados\n",
        "fan_data['id_verificado'] = id_verified_status # Se OCR leu algo\n",
        "fan_data['id_ocr_text'] = extracted_ocr_text # O texto bruto lido\n",
        "fan_data['id_structured_data'] = structured_data_from_ocr # Dados estruturados (tentativa)\n",
        "\n",
        "print(\"\\n--- Simula√ß√£o Conclu√≠da ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AjbhssW5i73i",
        "outputId": "426b54fa-915a-4447-a77c-c018ac7ab3cf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando Simula√ß√£o de Verifica√ß√£o de ID ---\n",
            "  Arquivo 'doc_exemplo.jpeg' encontrado (simulando upload).\n",
            "  Tentando ler texto da imagem com Tesseract OCR (pode levar um momento)...\n",
            "‚úÖ OCR conclu√≠do. Texto extra√≠do:\n",
            "-------------------------\n",
            "REP√öBLICA FEDERATIVA DO BRASIL\n",
            "GOVERNO FEDERAL\n",
            "\n",
            "Estado do Distrito Federal\n",
            "Secretaria de Seguran√ßa do Distrito Federal\n",
            "\n",
            "CARTEIRA DE IDENTIDADE\n",
            "\n",
            "Nome / Name.\n",
            "Maria Joana Ribeiro\n",
            "\n",
            "Nome Social / Social Name.\n",
            "\n",
            " \n",
            "\n",
            "Registro Geral - CPF / Personal Number Sexo / Sex\n",
            "\n",
            "088.794.450-73 F a\n",
            "\n",
            " \n",
            "\n",
            "Data de Nascimento / Date of Birth. Nacionalidade / Nationality\n",
            "01/01/1971 BRASILEIRA\n",
            "Naturalidade / Place of Birth Data de Validade / Date of Expiry\n",
            "Bras√≠lia 31/12/2024\n",
            "\n",
            " \n",
            "   \n",
            "\n",
            "‚ÄúAssinatura do Titular / Cardholder's S)\n",
            "\f\n",
            "-------------------------\n",
            "\n",
            "ü§ñ Tentando estruturar dados do OCR com Gemini...\n",
            "\n",
            "--- Estrutura√ß√£o IA (Tentativa) ---\n",
            "```json\n",
            "{\n",
            "  \"nome_completo\": \"Maria Joana Ribeiro\",\n",
            "  \"numero_cpf\": \"088.794.450-73\",\n",
            "  \"numero_rg\": \"N/A\",\n",
            "  \"data_nascimento\": \"01/01/1971\",\n",
            "  \"nome_mae\": \"N/A\",\n",
            "  \"nome_pai\": \"N/A\"\n",
            "}\n",
            "```\n",
            "\n",
            "\n",
            "JSON Extra√≠do:\n",
            "{'nome_completo': 'Maria Joana Ribeiro', 'numero_cpf': '088.794.450-73', 'numero_rg': 'N/A', 'data_nascimento': '01/01/1971', 'nome_mae': 'N/A', 'nome_pai': 'N/A'}\n",
            "\n",
            "--- Simula√ß√£o Conclu√≠da ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa 2.3: Vincula√ß√£o de Redes Sociais (SIMULADA/LIMITADA)\n",
        "\n",
        "A vincula√ß√£o real exigiria autentica√ß√£o OAuth com cada plataforma (Twitter/X, Instagram, Twitch, etc.). As APIs para leitura de dados de atividades, intera√ß√µes e p√°ginas seguidas s√£o muitas vezes restritas ou requerem aprova√ß√£o especial e podem ter custos associados. Fazer web scraping direto pode violar Termos de Servi√ßo.\n",
        "\n",
        "**Portanto, SIMULAREMOS a obten√ß√£o de dados agregados** como times seguidos ou intera√ß√µes recentes. Poder√≠amos opcionalmente adicionar uma an√°lise de IA sobre um texto de post fornecido pelo usu√°rio."
      ],
      "metadata": {
        "id": "LNJzNw87jGqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# C√©lula da Etapa 3 - Vincula√ß√£o Social (Revisada com Instagram)\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import re # Importar regex se n√£o estiver importado ainda\n",
        "import json # Importar json se n√£o estiver importado ainda\n",
        "\n",
        "# --- FUN√á√ïES AUXILIARES (Manter as mesmas: basic_scrape, analyze_text_with_gemini) ---\n",
        "def basic_scrape(url):\n",
        "    # ... (c√≥digo da fun√ß√£o basic_scrape exatamente como antes) ...\n",
        "    if not url or not url.startswith('http'):\n",
        "        return None, \"URL inv√°lida fornecida.\"\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "    try:\n",
        "        print(f\"  -> Tentando scraping b√°sico de: {url}\")\n",
        "        time.sleep(1)\n",
        "        response = requests.get(url, headers=headers, timeout=10) # Timeout 10s\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        bio_text = None\n",
        "        meta_desc = soup.find('meta', attrs={'name': 'description'}) # Tentar Meta Desc.\n",
        "        og_desc = soup.find('meta', property='og:description')  # Tentar OG Desc.\n",
        "\n",
        "        if meta_desc and meta_desc.get('content'):\n",
        "            bio_text = meta_desc['content']\n",
        "        elif og_desc and og_desc.get('content'):\n",
        "            bio_text = og_desc['content']\n",
        "        else: # Plano B: pegar texto do body (geralmente muito ru√≠do no insta)\n",
        "            # body = soup.find('body')\n",
        "            # if body:\n",
        "            #     bio_text = ' '.join(body.get_text(separator=' ', strip=True).split())[:1000]\n",
        "             pass # Desativar fallback para body no instagram, muito ineficaz\n",
        "\n",
        "\n",
        "        print(f\"  -> Scraping b√°sico retornou algum texto de Meta Tag: {'Sim' if bio_text else 'N√£o'}\")\n",
        "        return bio_text, \"Scraping de Meta Tags OK\" if bio_text else \"N√£o foi poss√≠vel extrair Bio/Descri√ß√£o das Meta Tags via scraping.\"\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "        return None, \"Erro: Timeout no scraping.\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        if e.response is not None and 400 <= e.response.status_code < 500:\n",
        "             return None, f\"Erro: Falha ao buscar ({e.response.status_code}) - Provavelmente requer login.\" # Mais espec√≠fico p/ Instagram\n",
        "        return None, f\"Erro: Falha na requisi√ß√£o de scraping ({e}).\"\n",
        "    except Exception as e:\n",
        "        return None, f\"Erro inesperado no scraping: {e}\"\n",
        "\n",
        "\n",
        "def analyze_text_with_gemini(text_to_analyze, platform):\n",
        "     # ... (c√≥digo da fun√ß√£o analyze_text_with_gemini exatamente como antes) ...\n",
        "    if not text_to_analyze or not gemini_model:\n",
        "        return \"An√°lise IA n√£o realizada (sem texto ou modelo).\", []\n",
        "\n",
        "    print(f\"  -> Analisando texto ({platform}) com Gemini...\")\n",
        "    prompt = f\"\"\"\n",
        "    Analise o seguinte texto (bio, descri√ß√£o ou posts de {platform})\n",
        "    para identificar afinidades com e-sports, Counter-Strike (CS2/CS:GO) e a equipe FURIA.\n",
        "\n",
        "    Texto Fornecido:\n",
        "    ---\n",
        "    {text_to_analyze}\n",
        "    ---\n",
        "\n",
        "    Responda concisamente:\n",
        "    1.  O texto sugere interesse em e-sports/CS? (Sim/N√£o/Incerto)\n",
        "    2.  H√° men√ß√µes diretas ou indiretas √† FURIA ou seus jogadores? (Sim/N√£o/Incerto)\n",
        "    3.  Liste at√© 5 palavras-chave ou termos relevantes para e-sports/CS/FURIA encontrados no texto. Se nada for relevante, retorne uma lista vazia.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        analysis = \"Erro: Resposta inesperada da IA.\" # Default\n",
        "        keywords = []\n",
        "        # Tratamento Robusto da Resposta\n",
        "        try:\n",
        "            analysis = response.text # Tenta acessar o texto diretamente\n",
        "            # Tentar extrair palavras-chave (regex simples)\n",
        "            lines = analysis.splitlines()\n",
        "            for line in lines:\n",
        "                if line.strip().startswith('3.'): # Se encontrar a linha 3\n",
        "                    potential_keys = re.findall(r'[\"\\']?\\b([A-Za-z√Ä-√ñ√ò-√∂√∏-√ø0-9 #@_]+)\\b[\"\\']?', line) # Regex melhorado\n",
        "                    keywords.extend([k.strip() for k in potential_keys if k.strip().lower() not in ['sim', 'n√£o', 'incerto', 'n/a'] and len(k.strip()) > 1])\n",
        "                    keywords = list(set(keywords))[:5]\n",
        "                    break\n",
        "        except ValueError: # Provavelmente bloqueio de seguran√ßa\n",
        "            if hasattr(response, 'prompt_feedback') and response.prompt_feedback.block_reason:\n",
        "               analysis = f\"‚ùå An√°lise bloqueada pelo filtro de seguran√ßa: {response.prompt_feedback.block_reason}\"\n",
        "            else:\n",
        "               analysis = \"‚ùå Erro: Gemini retornou uma resposta bloqueada ou inesperada.\"\n",
        "        except Exception as e_inner: # Qualquer outro erro acessando .text\n",
        "            analysis = f\"‚ùå Erro ao acessar texto da resposta Gemini: {e_inner}\"\n",
        "\n",
        "        print(\"  -> An√°lise IA conclu√≠da.\")\n",
        "        return analysis, keywords\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Erro durante an√°lise IA: {e}\")\n",
        "        return f\"Erro na an√°lise IA: {e}\", []\n",
        "\n",
        "# --- VINCULA√á√ÉO SOCIAL (AGORA COM INSTAGRAM) ---\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"      Etapa 3: Vincula√ß√£o Social (Simulada/Aprimorada)\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# -- 1. Twitter/X --\n",
        "print(\"\\n--- Twitter/X ---\")\n",
        "twitter_url = input(\"‚û°Ô∏è (Opcional) Cole a URL do seu perfil P√öBLICO no Twitter/X: \")\n",
        "twitter_bio_scraped, scrape_msg_twitter = basic_scrape(twitter_url)\n",
        "print(f\"   Resultado Scraping: {scrape_msg_twitter}\")\n",
        "twitter_desc = input(\"‚û°Ô∏è Descreva brevemente seus interesses ou cole 1-2 tweets seus sobre e-sports/FURIA: \")\n",
        "twitter_text_to_analyze = f\"Bio/Scraped (Twitter): {twitter_bio_scraped if twitter_bio_scraped else 'N/A'}\\n\\nDescri√ß√£o/Posts (Twitter): {twitter_desc}\"\n",
        "twitter_analysis, twitter_keywords = analyze_text_with_gemini(twitter_text_to_analyze, \"Twitter\")\n",
        "simulated_twitter_follows = [\"FURIA\"]\n",
        "if \"Gaules\" in twitter_keywords: simulated_twitter_follows.append(\"Gaules\")\n",
        "if \"Valorant\" in twitter_keywords: simulated_twitter_follows.append(\"Valorant Brasil\") # Exemplo\n",
        "\n",
        "fan_data['social_twitter_processed'] = {\n",
        "    \"profile_url_provided\": twitter_url if twitter_url else \"N√£o fornecida\",\n",
        "    \"scraping_result\": scrape_msg_twitter,\n",
        "    \"user_description\": twitter_desc if twitter_desc else \"N√£o fornecida\",\n",
        "    \"ai_analysis\": twitter_analysis,\n",
        "    \"derived_keywords\": twitter_keywords,\n",
        "    \"simulated_followed_orgs\": list(set(simulated_twitter_follows)),\n",
        "    \"link_status\": \"Partially Processed (IA + Simulation)\"\n",
        "}\n",
        "print(\"\\nAn√°lise e Dados Simulados para Twitter armazenados.\")\n",
        "\n",
        "# -- 2. Twitch --\n",
        "print(\"\\n--- Twitch ---\")\n",
        "twitch_url = input(\"‚û°Ô∏è (Opcional) Cole a URL do seu canal na Twitch: \")\n",
        "twitch_bio_scraped, scrape_msg_twitch = basic_scrape(twitch_url)\n",
        "print(f\"   Resultado Scraping: {scrape_msg_twitch}\")\n",
        "# Para Twitch, talvez analisar a descri√ß√£o raspada seja suficiente se houver\n",
        "twitch_text_to_analyze = twitch_bio_scraped if twitch_bio_scraped else \"\" # Usa s√≥ o scraping\n",
        "# Opcional: Pedir descri√ß√£o separada tamb√©m:\n",
        "# twitch_desc = input(\"‚û°Ô∏è (Opcional) Descreva seus streams ou jogos favoritos na Twitch: \")\n",
        "# twitch_text_to_analyze += f\"\\n\\nDescri√ß√£o Usu√°rio: {twitch_desc}\"\n",
        "twitch_analysis, twitch_keywords = analyze_text_with_gemini(twitch_text_to_analyze, \"Twitch\")\n",
        "simulated_twitch_follows = [\"FURIA\", \"BLASTPremier\"]\n",
        "if \"Gaules\" in twitch_keywords or \"Tribo\" in twitch_keywords : simulated_twitch_follows.append(\"Gaules\") # Exemplo\n",
        "if any(k in [\"Streamer\", \"CS Stream\"] for k in twitch_keywords): simulated_twitch_follows.append(\"Outro Streamer CS\")\n",
        "\n",
        "fan_data['social_twitch_processed'] = {\n",
        "    \"profile_url_provided\": twitch_url if twitch_url else \"N√£o fornecida\",\n",
        "    \"scraping_result\": scrape_msg_twitch,\n",
        "    # \"user_description\": twitch_desc if twitch_desc else \"N√£o fornecida\", # Se pedir\n",
        "    \"ai_analysis\": twitch_analysis,\n",
        "    \"derived_keywords\": twitch_keywords,\n",
        "    \"simulated_followed_channels\": list(set(simulated_twitch_follows)),\n",
        "     \"link_status\": \"Partially Processed (Scraping Attempt + IA + Simulation)\"\n",
        "}\n",
        "print(\"\\nAn√°lise e Dados Simulados para Twitch armazenados.\")\n",
        "\n",
        "\n",
        "# -- 3. Instagram --\n",
        "print(\"\\n--- Instagram ---\")\n",
        "instagram_url = input(\"‚û°Ô∏è Cole a URL do perfil P√öBLICO no Instagram: \")\n",
        "# Tentar scraping (provavelmente retornar√° pouco ou nada √∫til al√©m de meta tags)\n",
        "insta_bio_scraped, scrape_msg_insta = basic_scrape(instagram_url)\n",
        "print(f\"   Resultado Scraping: {scrape_msg_insta}\")\n",
        "# Pedir descri√ß√£o/bio pois scraping √© muito limitado\n",
        "instagram_desc = input(\"‚û°Ô∏è Descreva a bio do Instagram ou tipos de posts que voc√™ faz/v√™ sobre e-sports/FURIA: \")\n",
        "\n",
        "# A an√°lise IA depender√° principalmente da descri√ß√£o do usu√°rio\n",
        "insta_text_to_analyze = f\"Bio/Scraped (Instagram): {insta_bio_scraped if insta_bio_scraped else 'N/A'}\\n\\nDescri√ß√£o Usu√°rio (Instagram): {instagram_desc}\"\n",
        "instagram_analysis, instagram_keywords = analyze_text_with_gemini(insta_text_to_analyze, \"Instagram\")\n",
        "\n",
        "# Simular seguidos baseado nas keywords\n",
        "simulated_instagram_follows = [\"furia\"] # Nome geralmente em min√∫sculas no Insta\n",
        "if \"fallen\" in instagram_keywords: simulated_instagram_follows.append(\"fallen\")\n",
        "if \"kscerato\" in instagram_keywords: simulated_instagram_follows.append(\"kscerato\")\n",
        "if \"cs\" in instagram_keywords or \"counterstrike\" in instagram_keywords: simulated_instagram_follows.append(\"csgo_dev\") # Exemplo\n",
        "\n",
        "fan_data['social_instagram_processed'] = {\n",
        "    \"profile_url_provided\": instagram_url if instagram_url else \"N√£o fornecida\",\n",
        "    \"scraping_result\": scrape_msg_insta,\n",
        "    \"user_description\": instagram_desc if instagram_desc else \"N√£o fornecida\",\n",
        "    \"ai_analysis\": instagram_analysis,\n",
        "    \"derived_keywords\": instagram_keywords,\n",
        "    \"simulated_followed_accounts\": list(set(simulated_instagram_follows)), # Ex: Contas, n√£o canais\n",
        "     \"link_status\": \"Processed (User Input + IA)\" # Indica que depende mais do input\n",
        "}\n",
        "print(\"\\nAn√°lise e Dados Simulados para Instagram armazenados.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Vincula√ß√£o Social (Simulada/Aprimorada) Conclu√≠da ---\")\n",
        "\n",
        "# N√£o esque√ßa de atualizar a c√©lula do SUM√ÅRIO FINAL para exibir os dados\n",
        "# de fan_data['social_instagram_processed'] de forma similar √†s outras redes."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "IJo6-9tjjIaJ",
        "outputId": "6f7c818d-3675-44e6-a51f-af42926b0f63"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "      Etapa 3: Vincula√ß√£o Social (Simulada/Aprimorada)\n",
            "========================================\n",
            "\n",
            "--- Twitter/X ---\n",
            "‚û°Ô∏è (Opcional) Cole a URL do seu perfil P√öBLICO no Twitter/X: https://x.com/gaules/\n",
            "  -> Tentando scraping b√°sico de: https://x.com/gaules/\n",
            "  -> Scraping b√°sico retornou algum texto de Meta Tag: N√£o\n",
            "   Resultado Scraping: N√£o foi poss√≠vel extrair Bio/Descri√ß√£o das Meta Tags via scraping.\n",
            "‚û°Ô∏è Descreva brevemente seus interesses ou cole 1-2 tweets seus sobre e-sports/FURIA: \n",
            "  -> Analisando texto (Twitter) com Gemini...\n",
            "  -> An√°lise IA conclu√≠da.\n",
            "\n",
            "An√°lise e Dados Simulados para Twitter armazenados.\n",
            "\n",
            "--- Twitch ---\n",
            "‚û°Ô∏è (Opcional) Cole a URL do seu canal na Twitch: https://www.twitch.tv/gaules\n",
            "  -> Tentando scraping b√°sico de: https://www.twitch.tv/gaules\n",
            "  -> Scraping b√°sico retornou algum texto de Meta Tag: Sim\n",
            "   Resultado Scraping: Scraping de Meta Tags OK\n",
            "  -> Analisando texto (Twitch) com Gemini...\n",
            "  -> An√°lise IA conclu√≠da.\n",
            "\n",
            "An√°lise e Dados Simulados para Twitch armazenados.\n",
            "\n",
            "--- Instagram ---\n",
            "‚û°Ô∏è Cole a URL do perfil P√öBLICO no Instagram: Mais um guerreiro da Maior Tribo do Mundo! Atuei como jogador profissional de CS por quase uma d√©cada, fui o primeiro treinador a ser campe√£o do mundo em 2007 com o MIBR. Acertei um pouco, errei muito, ganhei bastante coisa e tbm perdi demais! Atualmente fa√ßo live todos os dias aqui na Twitch!\n",
            "   Resultado Scraping: URL inv√°lida fornecida.\n",
            "‚û°Ô∏è Descreva a bio do Instagram ou tipos de posts que voc√™ faz/v√™ sobre e-sports/FURIA: \n",
            "  -> Analisando texto (Instagram) com Gemini...\n",
            "  -> An√°lise IA conclu√≠da.\n",
            "\n",
            "An√°lise e Dados Simulados para Instagram armazenados.\n",
            "\n",
            "--- Vincula√ß√£o Social (Simulada/Aprimorada) Conclu√≠da ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapa 2.4: Sum√°rio do Perfil do F√£\n",
        "\n",
        "Abaixo est√° um resumo das informa√ß√µes coletadas e simuladas, formando o perfil \"Know Your Fan\"."
      ],
      "metadata": {
        "id": "mr1SZ1hPkYhj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VXU8EnUmsrYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Sum√°rio do Perfil (Apresenta√ß√£o Refinada) ---\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "import json # Para formatar o dicion√°rio de dados estruturados\n",
        "\n",
        "print(\"Gerando Sum√°rio do Perfil Formatado...\")\n",
        "\n",
        "# Fun√ß√£o auxiliar para formatar valores (evita erros com None)\n",
        "def format_value(value, default=\"N/A\"):\n",
        "    if value is None or value == '':\n",
        "        return default\n",
        "    if isinstance(value, bool):\n",
        "         return 'Sim (Simulado)' if value else 'N√£o (Simulado)' # Adaptado para o contexto\n",
        "    return str(value)\n",
        "\n",
        "# Iniciar a constru√ß√£o da string HTML\n",
        "html_output = \"\"\"\n",
        "<style>\n",
        "    /* === Container Principal === */\n",
        "    .profile-summary {\n",
        "        font-family: sans-serif;\n",
        "        border: 1px solid #e0e0e0; /* Borda cinza mais suave */\n",
        "        border-radius: 8px;\n",
        "        padding: 25px; /* Mais padding */\n",
        "        background-color: #ffffff; /* Fundo branco limpo */\n",
        "        margin-bottom: 20px;\n",
        "        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05); /* Sombra sutil */\n",
        "    }\n",
        "\n",
        "    /* === T√≠tulos === */\n",
        "    .profile-summary h2 { /* T√≠tulo Principal */\n",
        "        text-align: center;\n",
        "        color: #1a1a1a; /* Preto bem escuro */\n",
        "        border-bottom: 2px solid #FFC200; /* Amarelo Furia */\n",
        "        padding-bottom: 12px;\n",
        "        margin-top: 0;\n",
        "        margin-bottom: 25px; /* Mais espa√ßo abaixo */\n",
        "        font-size: 1.6em; /* Pouco maior */\n",
        "    }\n",
        "    .profile-summary h3 { /* T√≠tulos de Se√ß√£o */\n",
        "        color: #333333; /* Cinza escuro */\n",
        "        border-bottom: 1px solid #e0e0e0; /* Borda suave */\n",
        "        padding-bottom: 6px;\n",
        "        margin-top: 30px; /* Mais espa√ßo acima */\n",
        "        margin-bottom: 15px; /* Espa√ßo abaixo */\n",
        "        font-size: 1.3em;\n",
        "    }\n",
        "\n",
        "     /* === Listas e Itens === */\n",
        "    .profile-summary ul {\n",
        "        list-style: none;\n",
        "        padding-left: 0;\n",
        "    }\n",
        "    .profile-summary li {\n",
        "        margin-bottom: 10px; /* Pouco mais de espa√ßo */\n",
        "        line-height: 1.6;\n",
        "        color: #333; /* Cor padr√£o do texto dos itens */\n",
        "    }\n",
        "    /* R√≥tulos (ex: \"Nome Completo:\") */\n",
        "    .profile-summary strong {\n",
        "        color: #000000; /* Preto */\n",
        "        font-weight: 600; /* Semi-bold */\n",
        "        min-width: 190px; /* Ajustar largura se necess√°rio */\n",
        "        display: inline-block;\n",
        "        margin-right: 5px; /* Pequeno espa√ßo antes do valor */\n",
        "    }\n",
        "\n",
        "     /* === Subse√ß√µes (Social) === */\n",
        "    .profile-summary .sub-section {\n",
        "        margin-left: 0; /* Remover indenta√ß√£o para simplicidade? */\n",
        "        border-left: 3px solid #FFC200; /* Borda lateral Amarela */\n",
        "        padding: 10px 15px; /* Padding interno */\n",
        "        margin-top: 15px;\n",
        "        margin-bottom: 15px; /* Espa√ßo abaixo */\n",
        "        background-color: #f7f7f7; /* Fundo levemente diferente */\n",
        "        border-radius: 0 4px 4px 0; /* Cantos arredondados √† direita */\n",
        "    }\n",
        "     .profile-summary .sub-section h4 { /* T√≠tulo da subse√ß√£o (Twitter/Twitch) */\n",
        "          margin-top: 0;\n",
        "          margin-bottom: 10px;\n",
        "          color: #444;\n",
        "          font-size: 1.1em;\n",
        "      }\n",
        "       .profile-summary .sub-section ul { /* Listas dentro da subse√ß√£o */\n",
        "            margin-bottom: 0;\n",
        "        }\n",
        "       .profile-summary .sub-section li {\n",
        "            margin-bottom: 5px;\n",
        "            font-size: 0.95em;\n",
        "        }\n",
        "\n",
        "    /* === Blocos de Texto Pr√©-formatado (IMPORTANTE PARA CONTRASTE) === */\n",
        "    .profile-summary pre {\n",
        "        background-color: #e9ecef; /* Cinza MUITO CLARO para fundo */\n",
        "        color: #212529;          /* Texto QUASE PRETO para alto contraste */\n",
        "        padding: 12px;           /* Mais padding */\n",
        "        border-radius: 5px;      /* Cantos suaves */\n",
        "        white-space: pre-wrap;   /* Mant√©m quebras de linha e espa√ßos */\n",
        "        word-wrap: break-word;   /* Quebra palavras longas */\n",
        "        font-size: 0.9em;        /* Tamanho de fonte leg√≠vel */\n",
        "        border: 1px solid #ced4da; /* Borda sutil */\n",
        "        line-height: 1.4;        /* Espa√ßamento entre linhas */\n",
        "        max-height: 250px;       /* Altura m√°xima com scroll */\n",
        "        overflow-y: auto;        /* Adiciona scroll se exceder */\n",
        "    }\n",
        "\n",
        "    /* Bloco espec√≠fico da Pr√©via do OCR */\n",
        "    .profile-summary .ocr-preview {\n",
        "        background-color: #f8f9fa; /* Fundo um pouco diferente, ainda claro */\n",
        "        color: #495057;          /* Cinza escuro, mas n√£o preto total */\n",
        "        font-style: italic;       /* Mant√©m it√°lico */\n",
        "        max-height: 150px;       /* Altura para a pr√©via */\n",
        "        overflow-y: auto;\n",
        "        display: block;\n",
        "        padding: 8px 12px;\n",
        "        border: 1px dashed #adb5bd; /* Borda tracejada para indicar pr√©via/imperfei√ß√£o */\n",
        "        border-radius: 4px;\n",
        "        /* As outras propriedades (line-height, etc) v√™m do .profile-summary pre geral */\n",
        "    }\n",
        "</style>\n",
        "\n",
        "<div class=\"profile-summary\">\n",
        "    <h2>Perfil do F√£ (Know Your Fan)</h2>\n",
        "\n",
        "    <h3>Dados Pessoais (Fict√≠cios)</h3>\n",
        "    <ul>\n",
        "\"\"\"\n",
        "# Adicionar Dados Pessoais\n",
        "html_output += f\"<li><strong>Nome Completo:</strong> {format_value(fan_data.get('nome_completo'))}</li>\"\n",
        "html_output += f\"<li><strong>Localiza√ß√£o:</strong> {format_value(fan_data.get('cidade_estado'))}</li>\"\n",
        "html_output += f\"<li><strong>CPF:</strong> {format_value(fan_data.get('cpf'))}</li>\"\n",
        "\n",
        "html_output += \"\"\"\n",
        "    </ul>\n",
        "\n",
        "    <h3>Interesses em E-sports</h3>\n",
        "    <ul>\n",
        "\"\"\"\n",
        "# Adicionar Interesses\n",
        "html_output += f\"<li><strong>Jogo Favorito:</strong> {format_value(fan_data.get('jogo_favorito'))}</li>\"\n",
        "html_output += f\"<li><strong>Jogador FURIA Favorito:</strong> {format_value(fan_data.get('jogador_furia_fav'))}</li>\"\n",
        "html_output += f\"<li><strong>Assistiu Evento Presencial (√ölt. Ano):</strong> {format_value(fan_data.get('assistiu_evento_ano'))}</li>\"\n",
        "html_output += f\"<li><strong>Comprou Item E-sports (√ölt. Ano):</strong> {format_value(fan_data.get('comprou_item_ano'))}</li>\"\n",
        "html_output += f\"<li><strong>Tempo Acompanhando FURIA:</strong> {format_value(fan_data.get('tempo_acompanha_furia'))}</li>\"\n",
        "\n",
        "html_output += \"\"\"\n",
        "    </ul>\n",
        "\n",
        "    <h3>Verifica√ß√£o de Identidade (OCR)</h3>\n",
        "    <ul>\n",
        "\"\"\"\n",
        "# Adicionar Status da Verifica√ß√£o e Resultados OCR\n",
        "html_output += f\"<li><strong>Identidade Verificada:</strong> {format_value(fan_data.get('id_verificado'))}</li>\"\n",
        "ocr_preview = fan_data.get('id_ocr_text', 'N/A')\n",
        "if len(ocr_preview) > 200: # Limita pr√©via\n",
        "    ocr_preview = ocr_preview[:200] + '...'\n",
        "html_output += f\"<li><strong>Texto OCR (Pr√©via):</strong> <pre class='ocr-preview'>{ocr_preview}</pre></li>\"\n",
        "# Formatar o dicion√°rio de dados estruturados como JSON para melhor visualiza√ß√£o\n",
        "structured_data = fan_data.get('id_structured_data', {})\n",
        "formatted_json = json.dumps(structured_data, indent=2, ensure_ascii=False) # Pretty print JSON\n",
        "html_output += f\"<li><strong>Dados Estruturados (IA):</strong> <pre>{formatted_json}</pre></li>\"\n",
        "\n",
        "\n",
        "# --- Bloco para Redes Sociais Processadas ---\n",
        "\n",
        "html_output += \"\"\"\n",
        "    <h3>Vincula√ß√£o Social (Processada/Simulada)</h3>\n",
        "\"\"\"\n",
        "\n",
        "# --- Twitter ---\n",
        "twitter_data = fan_data.get('social_twitter_processed') # Busca a chave correta\n",
        "if twitter_data:\n",
        "  html_output += \"\"\"\n",
        "      <div class=\"sub-section\">\n",
        "          <h4>Twitter/X</h4>\n",
        "          <ul>\n",
        "  \"\"\"\n",
        "  html_output += f\"<li><strong>URL Fornecida:</strong> {format_value(twitter_data.get('profile_url_provided'))}</li>\"\n",
        "  html_output += f\"<li><strong>Resultado Scraping:</strong> {format_value(twitter_data.get('scraping_result'))}</li>\"\n",
        "  html_output += f\"<li><strong>Descri√ß√£o Usu√°rio:</strong> {format_value(twitter_data.get('user_description'))}</li>\"\n",
        "  keywords_tw_list = twitter_data.get('derived_keywords', [])\n",
        "  keywords_tw_str = ', '.join(keywords_tw_list) if keywords_tw_list else 'Nenhuma'\n",
        "  html_output += f\"<li><strong>Palavras-Chave (IA):</strong> {format_value(keywords_tw_str)}</li>\"\n",
        "  follows_tw_list = twitter_data.get('simulated_followed_orgs', [])\n",
        "  follows_tw_str = ', '.join(follows_tw_list) if follows_tw_list else 'Nenhuma'\n",
        "  html_output += f\"<li><strong>Organiza√ß√µes Seguidas:</strong> {format_value(follows_tw_str)}</li>\"\n",
        "  html_output += f\"<li><strong>An√°lise IA:</strong><pre>{format_value(twitter_data.get('ai_analysis'))}</pre></li>\"\n",
        "  html_output += \"</ul></div>\"\n",
        "\n",
        "# --- Twitch ---\n",
        "twitch_data = fan_data.get('social_twitch_processed') # Busca a chave correta\n",
        "if twitch_data:\n",
        "  html_output += \"\"\"\n",
        "      <div class=\"sub-section\">\n",
        "          <h4>Twitch</h4>\n",
        "          <ul>\n",
        "  \"\"\"\n",
        "  html_output += f\"<li><strong>URL Fornecida:</strong> {format_value(twitch_data.get('profile_url_provided'))}</li>\"\n",
        "  html_output += f\"<li><strong>Resultado Scraping:</strong> {format_value(twitch_data.get('scraping_result'))}</li>\"\n",
        "  keywords_ttv_list = twitch_data.get('derived_keywords', [])\n",
        "  keywords_ttv_str = ', '.join(keywords_ttv_list) if keywords_ttv_list else 'Nenhuma'\n",
        "  html_output += f\"<li><strong>Palavras-Chave (IA):</strong> {format_value(keywords_ttv_str)}</li>\"\n",
        "  follows_ttv_list = twitch_data.get('simulated_followed_channels', [])\n",
        "  follows_ttv_str = ', '.join(follows_ttv_list) if follows_ttv_list else 'Nenhuma'\n",
        "  html_output += f\"<li><strong>Canais Seguidos:</strong> {format_value(follows_ttv_str)}</li>\"\n",
        "  html_output += f\"<li><strong>An√°lise IA (Scraping):</strong><pre>{format_value(twitch_data.get('ai_analysis'))}</pre></li>\"\n",
        "  html_output += \"</ul></div>\"\n",
        "\n",
        "\n",
        "# --- Instagram ---\n",
        "instagram_data = fan_data.get('social_instagram_processed') # Busca a chave correta\n",
        "if instagram_data:\n",
        "  html_output += \"\"\"\n",
        "      <div class=\"sub-section\">\n",
        "          <h4>Instagram</h4>\n",
        "          <ul>\n",
        "  \"\"\"\n",
        "  html_output += f\"<li><strong>URL Fornecida:</strong> {format_value(instagram_data.get('profile_url_provided'))}</li>\"\n",
        "  html_output += f\"<li><strong>Resultado Scraping (Meta Tags):</strong> {format_value(instagram_data.get('scraping_result'))}</li>\"\n",
        "  html_output += f\"<li><strong>Descri√ß√£o Usu√°rio:</strong> {format_value(instagram_data.get('user_description'))}</li>\"\n",
        "  keywords_ig_list = instagram_data.get('derived_keywords', [])\n",
        "  keywords_ig_str = ', '.join(keywords_ig_list) if keywords_ig_list else 'Nenhuma'\n",
        "  html_output += f\"<li><strong>Palavras-Chave (IA):</strong> {format_value(keywords_ig_str)}</li>\"\n",
        "  follows_ig_list = instagram_data.get('simulated_followed_accounts', [])\n",
        "  follows_ig_str = ', '.join(follows_ig_list) if follows_ig_list else 'Nenhuma'\n",
        "  html_output += f\"<li><strong>Contas Seguidas:</strong> {format_value(follows_ig_str)}</li>\"\n",
        "  html_output += f\"<li><strong>An√°lise IA (Descri√ß√£o/Scraping):</strong><pre>{format_value(instagram_data.get('ai_analysis'))}</pre></li>\"\n",
        "  html_output += \"</ul></div>\"\n",
        "\n",
        "# --- FIM do Bloco social ---\n",
        "\n",
        "\n",
        "\n",
        "# Exibe o HTML renderizado na c√©lula de sa√≠da\n",
        "display(HTML(html_output))\n",
        "\n",
        "print(\"\\n--- FIM DO SUM√ÅRIO ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vOSoRcnHkbSe",
        "outputId": "9c01f0e7-d980-49cb-b4ed-ab0899d58524"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gerando Sum√°rio do Perfil Formatado...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* === Container Principal === */\n",
              "    .profile-summary {\n",
              "        font-family: sans-serif;\n",
              "        border: 1px solid #e0e0e0; /* Borda cinza mais suave */\n",
              "        border-radius: 8px;\n",
              "        padding: 25px; /* Mais padding */\n",
              "        background-color: #ffffff; /* Fundo branco limpo */\n",
              "        margin-bottom: 20px;\n",
              "        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05); /* Sombra sutil */\n",
              "    }\n",
              "\n",
              "    /* === T√≠tulos === */\n",
              "    .profile-summary h2 { /* T√≠tulo Principal */\n",
              "        text-align: center;\n",
              "        color: #1a1a1a; /* Preto bem escuro */\n",
              "        border-bottom: 2px solid #FFC200; /* Amarelo Furia */\n",
              "        padding-bottom: 12px;\n",
              "        margin-top: 0;\n",
              "        margin-bottom: 25px; /* Mais espa√ßo abaixo */\n",
              "        font-size: 1.6em; /* Pouco maior */\n",
              "    }\n",
              "    .profile-summary h3 { /* T√≠tulos de Se√ß√£o */\n",
              "        color: #333333; /* Cinza escuro */\n",
              "        border-bottom: 1px solid #e0e0e0; /* Borda suave */\n",
              "        padding-bottom: 6px;\n",
              "        margin-top: 30px; /* Mais espa√ßo acima */\n",
              "        margin-bottom: 15px; /* Espa√ßo abaixo */\n",
              "        font-size: 1.3em;\n",
              "    }\n",
              "\n",
              "     /* === Listas e Itens === */\n",
              "    .profile-summary ul {\n",
              "        list-style: none;\n",
              "        padding-left: 0;\n",
              "    }\n",
              "    .profile-summary li {\n",
              "        margin-bottom: 10px; /* Pouco mais de espa√ßo */\n",
              "        line-height: 1.6;\n",
              "        color: #333; /* Cor padr√£o do texto dos itens */\n",
              "    }\n",
              "    /* R√≥tulos (ex: \"Nome Completo:\") */\n",
              "    .profile-summary strong {\n",
              "        color: #000000; /* Preto */\n",
              "        font-weight: 600; /* Semi-bold */\n",
              "        min-width: 190px; /* Ajustar largura se necess√°rio */\n",
              "        display: inline-block;\n",
              "        margin-right: 5px; /* Pequeno espa√ßo antes do valor */\n",
              "    }\n",
              "\n",
              "     /* === Subse√ß√µes (Social) === */\n",
              "    .profile-summary .sub-section {\n",
              "        margin-left: 0; /* Remover indenta√ß√£o para simplicidade? */\n",
              "        border-left: 3px solid #FFC200; /* Borda lateral Amarela */\n",
              "        padding: 10px 15px; /* Padding interno */\n",
              "        margin-top: 15px;\n",
              "        margin-bottom: 15px; /* Espa√ßo abaixo */\n",
              "        background-color: #f7f7f7; /* Fundo levemente diferente */\n",
              "        border-radius: 0 4px 4px 0; /* Cantos arredondados √† direita */\n",
              "    }\n",
              "     .profile-summary .sub-section h4 { /* T√≠tulo da subse√ß√£o (Twitter/Twitch) */\n",
              "          margin-top: 0;\n",
              "          margin-bottom: 10px;\n",
              "          color: #444;\n",
              "          font-size: 1.1em;\n",
              "      }\n",
              "       .profile-summary .sub-section ul { /* Listas dentro da subse√ß√£o */\n",
              "            margin-bottom: 0;\n",
              "        }\n",
              "       .profile-summary .sub-section li {\n",
              "            margin-bottom: 5px;\n",
              "            font-size: 0.95em;\n",
              "        }\n",
              "\n",
              "    /* === Blocos de Texto Pr√©-formatado (IMPORTANTE PARA CONTRASTE) === */\n",
              "    .profile-summary pre {\n",
              "        background-color: #e9ecef; /* Cinza MUITO CLARO para fundo */\n",
              "        color: #212529;          /* Texto QUASE PRETO para alto contraste */\n",
              "        padding: 12px;           /* Mais padding */\n",
              "        border-radius: 5px;      /* Cantos suaves */\n",
              "        white-space: pre-wrap;   /* Mant√©m quebras de linha e espa√ßos */\n",
              "        word-wrap: break-word;   /* Quebra palavras longas */\n",
              "        font-size: 0.9em;        /* Tamanho de fonte leg√≠vel */\n",
              "        border: 1px solid #ced4da; /* Borda sutil */\n",
              "        line-height: 1.4;        /* Espa√ßamento entre linhas */\n",
              "        max-height: 250px;       /* Altura m√°xima com scroll */\n",
              "        overflow-y: auto;        /* Adiciona scroll se exceder */\n",
              "    }\n",
              "\n",
              "    /* Bloco espec√≠fico da Pr√©via do OCR */\n",
              "    .profile-summary .ocr-preview {\n",
              "        background-color: #f8f9fa; /* Fundo um pouco diferente, ainda claro */\n",
              "        color: #495057;          /* Cinza escuro, mas n√£o preto total */\n",
              "        font-style: italic;       /* Mant√©m it√°lico */\n",
              "        max-height: 150px;       /* Altura para a pr√©via */\n",
              "        overflow-y: auto;\n",
              "        display: block;\n",
              "        padding: 8px 12px;\n",
              "        border: 1px dashed #adb5bd; /* Borda tracejada para indicar pr√©via/imperfei√ß√£o */\n",
              "        border-radius: 4px;\n",
              "        /* As outras propriedades (line-height, etc) v√™m do .profile-summary pre geral */\n",
              "    }\n",
              "</style>\n",
              "\n",
              "<div class=\"profile-summary\">\n",
              "    <h2>Perfil do F√£ (Know Your Fan)</h2>\n",
              "\n",
              "    <h3>Dados Pessoais (Fict√≠cios)</h3>\n",
              "    <ul>\n",
              "<li><strong>Nome Completo:</strong> Alex Silva (Fict√≠cio)</li><li><strong>Localiza√ß√£o:</strong> S√£o Paulo, SP (Fict√≠cio)</li><li><strong>CPF:</strong> Omitido/Fict√≠cio (N√£o Coletado)</li>\n",
              "    </ul>\n",
              "\n",
              "    <h3>Interesses em E-sports</h3>\n",
              "    <ul>\n",
              "<li><strong>Jogo Favorito:</strong> c2</li><li><strong>Jogador FURIA Favorito:</strong> fallen</li><li><strong>Assistiu Evento Presencial (√ölt. Ano):</strong> nao</li><li><strong>Comprou Item E-sports (√ölt. Ano):</strong> sim</li><li><strong>Tempo Acompanhando FURIA:</strong> 4anos</li>\n",
              "    </ul>\n",
              "\n",
              "    <h3>Verifica√ß√£o de Identidade (OCR)</h3>\n",
              "    <ul>\n",
              "<li><strong>Identidade Verificada:</strong> Sim (Simulado)</li><li><strong>Texto OCR (Pr√©via):</strong> <pre class='ocr-preview'>REP√öBLICA FEDERATIVA DO BRASIL\n",
              "GOVERNO FEDERAL\n",
              "\n",
              "Estado do Distrito Federal\n",
              "Secretaria de Seguran√ßa do Distrito Federal\n",
              "\n",
              "CARTEIRA DE IDENTIDADE\n",
              "\n",
              "Nome / Name.\n",
              "Maria Joana Ribeiro\n",
              "\n",
              "Nome Social / Social N...</pre></li><li><strong>Dados Estruturados (IA):</strong> <pre>{\n",
              "  \"nome_completo\": \"Maria Joana Ribeiro\",\n",
              "  \"numero_cpf\": \"088.794.450-73\",\n",
              "  \"numero_rg\": \"N/A\",\n",
              "  \"data_nascimento\": \"01/01/1971\",\n",
              "  \"nome_mae\": \"N/A\",\n",
              "  \"nome_pai\": \"N/A\"\n",
              "}</pre></li>\n",
              "    <h3>Vincula√ß√£o Social (Processada/Simulada)</h3>\n",
              "\n",
              "      <div class=\"sub-section\">\n",
              "          <h4>Twitter/X</h4>\n",
              "          <ul>\n",
              "  <li><strong>URL Fornecida:</strong> https://x.com/gaules/</li><li><strong>Resultado Scraping:</strong> N√£o foi poss√≠vel extrair Bio/Descri√ß√£o das Meta Tags via scraping.</li><li><strong>Descri√ß√£o Usu√°rio:</strong> N√£o fornecida</li><li><strong>Palavras-Chave (IA):</strong> Nenhuma</li><li><strong>Organiza√ß√µes Seguidas:</strong> FURIA</li><li><strong>An√°lise IA:</strong><pre>1. N√£o\n",
              "2. N√£o\n",
              "3. []\n",
              "</pre></li></ul></div>\n",
              "      <div class=\"sub-section\">\n",
              "          <h4>Twitch</h4>\n",
              "          <ul>\n",
              "  <li><strong>URL Fornecida:</strong> https://www.twitch.tv/gaules</li><li><strong>Resultado Scraping:</strong> Scraping de Meta Tags OK</li><li><strong>Palavras-Chave (IA):</strong> sports, pode ser considerado se for uma equipe de esports, G3X, Gaules, Kings League</li><li><strong>Canais Seguidos:</strong> BLASTPremier, Gaules, FURIA</li><li><strong>An√°lise IA (Scraping):</strong><pre>1. Sim\n",
              "2. N√£o\n",
              "3. e-sports, Gaules, Kings League, AO VIVO,  G3X (pode ser considerado se for uma equipe de esports)\n",
              "</pre></li></ul></div>\n",
              "      <div class=\"sub-section\">\n",
              "          <h4>Instagram</h4>\n",
              "          <ul>\n",
              "  <li><strong>URL Fornecida:</strong> Mais um guerreiro da Maior Tribo do Mundo! Atuei como jogador profissional de CS por quase uma d√©cada, fui o primeiro treinador a ser campe√£o do mundo em 2007 com o MIBR. Acertei um pouco, errei muito, ganhei bastante coisa e tbm perdi demais! Atualmente fa√ßo live todos os dias aqui na Twitch!</li><li><strong>Resultado Scraping (Meta Tags):</strong> URL inv√°lida fornecida.</li><li><strong>Descri√ß√£o Usu√°rio:</strong> N√£o fornecida</li><li><strong>Palavras-Chave (IA):</strong> Nenhuma</li><li><strong>Contas Seguidas:</strong> furia</li><li><strong>An√°lise IA (Descri√ß√£o/Scraping):</strong><pre>1. N√£o\n",
              "2. N√£o\n",
              "3. []\n",
              "</pre></li></ul></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- FIM DO SUM√ÅRIO ---\n"
          ]
        }
      ]
    }
  ]
}